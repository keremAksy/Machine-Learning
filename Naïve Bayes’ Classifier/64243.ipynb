{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "64243.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFwHupRq8v7a"
      },
      "source": [
        "#**Kerem Aksoy**\n",
        "#HomeWork 2 : Naive Bayes' Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUHBol-t9bpu"
      },
      "source": [
        "Importing the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68sYJdcr8_qJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol7Ll_hk9vG9"
      },
      "source": [
        "Importing the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb7-eCqfA_3l"
      },
      "source": [
        "data_setY =np.genfromtxt(\"hw02_labels.csv\",delimiter = \",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCckrDV19v3g"
      },
      "source": [
        "data_setX=np.genfromtxt(\"hw02_images.csv\", delimiter = \",\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb2qIQX3_0uq"
      },
      "source": [
        "Splitting the set into traning and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVezpPxg_3Jj"
      },
      "source": [
        "x_train = data_setX[:30000,:]\n",
        "y_train = data_setY[:30000]\n",
        "\n",
        "x_test = data_setX[30000:,:]\n",
        "y_test = data_setY[30000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3w4a-YnD2Jn"
      },
      "source": [
        "Finding prior probabilites for classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrPNzcfvEPGi"
      },
      "source": [
        "class_priors = [0,0,0,0,0] #This will hold number of examples which belongs to each class\n",
        "totalNumber = len(y_train)\n",
        "for i in range(1,6):\n",
        "  temp = y_train[y_train == i]\n",
        "  class_priors [i-1] = len(temp) / totalNumber"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqJcAmOpGb2U"
      },
      "source": [
        "Finding the means values of 5 classes for each feature "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ9gqDpwG94J"
      },
      "source": [
        "means = []\n",
        "for i in range(1,6):\n",
        "  temp = x_train[y_train == i]\n",
        "  temp_list = temp.mean(axis=0)\n",
        "  means.append(temp_list)\n",
        "sample_means = np.array(means)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xkPqwFTT94X"
      },
      "source": [
        "Finding derivations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu8pfA2_UCzM"
      },
      "source": [
        "deviations = []\n",
        "for i in range(1,6):\n",
        "  temp = np.sqrt(np.mean((x_train[y_train == i]-sample_means[i-1])**2,axis=0))\n",
        "  deviations.append(temp)\n",
        "sample_deviations = np.array(deviations)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJA69tggYhl3"
      },
      "source": [
        "Creating the posterier probabilty finder function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ2fpEIDdQ_9"
      },
      "source": [
        "import math\n",
        "#In this function, after calculating the value, I take the maximum probability label to choose which one\n",
        "#This fuction returns the label which x belongs to given x\n",
        "def findPosterior_andDecide(x):\n",
        "    scoreList = []\n",
        "    for i in range(1,6):\n",
        "      temp_prob = sum((-0.5*np.log(2*math.pi)) - (np.log(sample_deviations[i-1])) - ((x-sample_means[i-1])*(x-sample_means[i-1])/(2*sample_deviations[i-1]*sample_deviations[i-1]))) + class_priors[i-1] \n",
        "      scoreList.append(temp_prob)\n",
        "    max_prob = max(scoreList)\n",
        "    predicted_label = scoreList.index(max_prob) + 1 #Since our labels starst from 1 to 5\n",
        "    return predicted_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL4hO9uJxF9O"
      },
      "source": [
        "Now we need to generate confusion matrix to see the succes of the model for both training and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Zpz9HAr2Yv"
      },
      "source": [
        "Confusion Matrix For Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoC_p8QKvnOq"
      },
      "source": [
        "f = lambda x: findPosterior_andDecide(x) #Creating Lambda Experession\n",
        "#This expression will be used to calculate the prediction for each row(example/point) in the training and test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjjBbmqSr8Ug",
        "outputId": "dbf25a44-0c2d-4cfb-8834-35369a6dda3d"
      },
      "source": [
        "f = lambda x: findPosterior_andDecide(x)\n",
        "training_predict = np.apply_along_axis(f,1,x_train)\n",
        "confusionMatrixTest = confusion_matrix(training_predict,y_train)\n",
        "print(confusionMatrixTest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3685   49    4  679    6]\n",
            " [1430 5667 1140 1380  532]\n",
            " [ 508  208 4670 2948  893]\n",
            " [ 234   60  123  687  180]\n",
            " [ 143   16   63  306 4389]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYMgCOmmr5n-"
      },
      "source": [
        "Confision Matrix For Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tURVa7W6r8jy",
        "outputId": "3c05be96-3cca-4cfa-dc55-dd3933c514cb"
      },
      "source": [
        "test_predict = np.apply_along_axis(f,1,x_test)\n",
        "confusionMatrixTest = np.array(confusion_matrix(test_predict,y_test))\n",
        "print(confusionMatrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[597   6   0 114   1]\n",
            " [237 955 188 267  81]\n",
            " [ 92  25 785 462 167]\n",
            " [ 34  11  16 109  29]\n",
            " [ 40   3  11  48 722]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vij1eRZtv5Tl"
      },
      "source": [
        ""
      ]
    }
  ]
}